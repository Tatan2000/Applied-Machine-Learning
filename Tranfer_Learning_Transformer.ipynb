{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f863dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\",force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee2c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/sentiment_analysis.zip\", 'r')\n",
    "zip_ref.extractall(\"/content/files/\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d268ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification,get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2711f58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"/content/files/train.csv\",encoding=\"iso-8859-1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3800c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def data_preprocessing(txt):\n",
    "    regex = r'[^\\w\\s]|[\\U0001f600-\\U0001f64f\\U0001f300-\\U0001f5ff\\U0001f680-\\U0001f6ff\\U0001f1e0-\\U0001f1ff]'\n",
    "    txt=re.sub(regex,\" \",txt)\n",
    "    txt=re.sub(\"\\.|\\,|\\/|\\-\",\" \",txt) \n",
    "    txt=re.sub(\"\\s*\\s\",\" \",txt)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b21769",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df.loc[i,\"txt\"]=data_preprocessing(str(df.loc[i,\"txt\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e239b597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment\"]=df[\"sentiment\"].replace({\"negative\":0,\"neutral\":1,\"positive\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd748e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[[\"txt\",\"sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347fc7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "train_txt,test_txt,train_lbl,test_lbl=train_test_split(df[\"txt\"],df[\"sentiment\"],test_size=0.5)\n",
    "valid_txt,test_txt,valid_lbl,test_lbl=train_test_split(test_txt,test_lbl,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f46a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import torch\n",
    "import seaborn as sns\n",
    "import transformers\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acb72e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "classes = 3\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bddc21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_example_to_feature(review):\n",
    "    return bert_tokenizer.encode_plus(review, add_special_tokens = True, max_length = 512, padding='max_length',\n",
    "                truncation=True, return_attention_mask = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0913e6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_example_to_dict(input_ids, attention_masks, token_type_ids, label):\n",
    "    return {\"input_ids\": input_ids, \"token_type_ids\": token_type_ids, \"attention_mask\": attention_masks,}, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ef4438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_examples(ds):\n",
    "  \n",
    "    input_ids_list = []\n",
    "    token_type_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    label_list = []\n",
    "    for review, label in ds:\n",
    "        bert_input = convert_example_to_feature(review)\n",
    "        input_ids_list.append(bert_input['input_ids'])\n",
    "        token_type_ids_list.append(bert_input['token_type_ids'])\n",
    "        attention_mask_list.append(bert_input['attention_mask'])\n",
    "        label_list.append([label])\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_example_to_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bcb093",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "ds_train = zip(train_txt, train_lbl)\n",
    "ds_test = zip(test_txt, test_lbl)\n",
    "ds_train_encoded = encode_examples(ds_train).shuffle(len(train_txt)).batch(batch_size)\n",
    "ds_test_encoded = encode_examples(ds_test).batch(batch_size)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2489294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'bert_model.h5'\n",
    "\n",
    "path = \"/content/\"\n",
    "\n",
    "## Initialize pre-built BERT-based classifier from transformers\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_classes)\n",
    "\n",
    "bert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220eaf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 2e-5\n",
    "\n",
    "\n",
    "number_of_epochs = 5\n",
    "\n",
    "# choosing Adam optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08)\n",
    "\n",
    "\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "bert_model.compile(loss=loss, optimizer=optimizer, metrics=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a373f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "past = bert_model.fit(ds_train_encoded, batch_size=batch_size, epochs=number_of_epochs, validation_data=ds_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faee1892",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model.save_weights(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fa3c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "\n",
    "matplotlib.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8732283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot1(past):\n",
    "    acc = past.past['accuracy']\n",
    "    val_acc = past.past['val_accuracy']\n",
    "    loss = past.past['loss']\n",
    "    val_loss = past.past['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    ## Accuracy plot\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    ## Loss plot\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711644de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2(past):\n",
    "    pd.DataFrame(past.past).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "plot2(past)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac60f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model.evaluate(ds_test_encoded, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fc539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = bert_model.predict(ds_test_encoded, batch_size=batch_size)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed18c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_class = y_test_pred[0].argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fd8488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
