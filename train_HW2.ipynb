{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05739380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, accuracy_score, precision_score, recall_score, auc, classification_report, ConfusionMatrixDisplay, make_scorer\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc448397",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///database/mlflow.db\")\n",
    "experiment = mlflow.set_experiment(\"SMS Spam Detection\")\n",
    "\n",
    "\n",
    "experiment_id = experiment.experiment_id\n",
    "print(\"Experiment ID:\", experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56824850",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_save_path = os.path.join('data','train.csv')\n",
    "val_save_path = os.path.join('data','val.csv')\n",
    "test_save_path = os.path.join('data','test.csv')\n",
    "\n",
    "train_val_test_save_paths = [train_save_path, val_save_path, test_save_path]\n",
    "\n",
    "train_val_test_save_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59009eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_val_test(train_val_test_save_paths, oversampler=None):\n",
    "    train_data = pd.read_csv(train_val_test_save_paths[0])\n",
    "    val_data = pd.read_csv(train_val_test_save_paths[1])\n",
    "    test_data = pd.read_csv(train_val_test_save_paths[2])\n",
    "    \n",
    "    \n",
    "    y_train = train_data['label']\n",
    "    X_train = train_data.drop('label', axis=1)\n",
    "\n",
    "   \n",
    "    if oversampler:\n",
    "        X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "    y_val = val_data['label']\n",
    "    X_val = val_data.drop('label', axis=1)\n",
    "\n",
    "    y_test = test_data['label']\n",
    "    X_test = test_data.drop('label', axis=1)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val ,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbf21fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, X_val, y_train, y_val, classifier, param_grid):\n",
    "    \n",
    "    classifier_name = classifier.__class__.__name__\n",
    "    run_name = classifier_name + str(\"_run\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    best_model = classifier\n",
    "    \n",
    "    \n",
    "    best_precision = 0.0\n",
    "\n",
    "   \n",
    "    param_list = list(product(*param_grid.values()))\n",
    "\n",
    "    for param in param_list:\n",
    "        \n",
    "        with mlflow.start_run(run_name=run_name, experiment_id=experiment_id):\n",
    "            \n",
    "            mlflow.set_tags(run_tags)\n",
    "            \n",
    "            \n",
    "            param_dict = dict(zip(param_grid.keys(), param))\n",
    "            \n",
    "            mlflow.log_params(param_dict)\n",
    "            \n",
    "            \n",
    "            model = classifier.set_params(**param_dict)\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            \n",
    "            y_val_hat = model.predict(X_val)\n",
    "            y_val_prob = model.predict_proba(X_val)[:, 1]\n",
    "            \n",
    "           \n",
    "            current_precision = precision_score(y_val, y_val_hat, average='micro')\n",
    "            # log precision_score\n",
    "            mlflow.log_metric(key=\"precision\", value=current_precision)\n",
    "\n",
    "            # calculate the area under the precision-recall curve (AUCPR)\n",
    "            precision, recall, thresholds = precision_recall_curve(y_val, y_val_prob)\n",
    "            aucpr = auc(recall, precision)\n",
    "            # log aucpr\n",
    "            mlflow.log_metric(key=\"AUCPR\", value=aucpr)\n",
    "\n",
    "           \n",
    "            mlflow.sklearn.log_model(model, classifier_name)\n",
    "\n",
    "            \n",
    "            if current_precision > best_precision:\n",
    "                best_precision = current_precision\n",
    "                best_model = model\n",
    "                \n",
    "                print(\"Current Best Precision on Val: %.3f\" % best_precision)\n",
    "    \n",
    "    \n",
    "    print(\"Overall Best Model:\", best_model)\n",
    "    print(\"Overall Best Precision on Val: %.3f\" % best_precision)\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e1918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {'penalty': ['l1', 'l2'],\n",
    "              'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "              'solver': ['liblinear'],\n",
    "              'max_iter': [100, 200, 500]}\n",
    "\n",
    "best_logit = train_model(\n",
    "                            X_train=X_train,\n",
    "                            X_val=X_val,\n",
    "                            y_train=y_train,\n",
    "                            y_val=y_val,\n",
    "                            classifier=classifier,\n",
    "                            param_grid=param_grid\n",
    "                            )\n",
    "\n",
    "\n",
    "y_test_prob = best_logit.predict_proba(X_test)[:, 1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_test_prob)\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, color='blue', label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(\"Test Precision-Recall curve\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate the Area under the PRCurve\n",
    "aucpr = auc(recall, precision)\n",
    "print(\"Area under the PRCurve for Test Data:\", aucpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa65c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "best_rfc = train_model(\n",
    "                            X_train=X_train,\n",
    "                            X_val=X_val,\n",
    "                            y_train=y_train,\n",
    "                            y_val=y_val,\n",
    "                            classifier=classifier,\n",
    "                            param_grid=param_grid\n",
    "                            )\n",
    "\n",
    "\n",
    "y_test_prob = best_rfc.predict_proba(X_test)[:, 1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_test_prob)\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, color='blue', label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(\"Test Precision-Recall curve\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate the Area under the PRCurve\n",
    "aucpr = auc(recall, precision)\n",
    "print(\"Area under the PRCurve for Test Data:\", aucpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507135b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_hat = best_logit.predict(X_test)\n",
    "\n",
    "# show confusion matrix\n",
    "cm_display = ConfusionMatrixDisplay.from_predictions(y_test, y_test_hat, values_format='.5g')\n",
    "plt.title(\"Logistic Regression\")\n",
    "plt.show()\n",
    "\n",
    "# print the classification report\n",
    "print(classification_report(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de757e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_hat = best_rfc.predict(X_test)\n",
    "\n",
    "# show confusion matrix\n",
    "cm_display = ConfusionMatrixDisplay.from_predictions(y_test, y_test_hat, values_format='.5g')\n",
    "plt.title(\"Random Forest Classifier\")\n",
    "plt.show()\n",
    "\n",
    "# print the classification report\n",
    "print(classification_report(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d3a32e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
